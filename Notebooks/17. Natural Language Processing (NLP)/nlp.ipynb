{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08cf6013",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "documents = []\n",
    "\n",
    "for category in movie_reviews.categories():\n",
    "    for fileid in movie_reviews.fileids(category):\n",
    "        documents.append((movie_reviews.words(fileid), category))\n",
    "\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0823feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "punctuations = list(string.punctuation)\n",
    "\n",
    "stop_words.extend(punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "624a592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26cbb680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "\n",
    "def simple_pos_tag(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dba30cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(review):\n",
    "    output_review = []\n",
    "\n",
    "    for word in review:\n",
    "        if word.lower() not in stop_words:\n",
    "            pos = pos_tag([word])\n",
    "\n",
    "            lemmatizer_word = lemmatizer.lemmatize(word, pos=simple_pos_tag(pos[0][1]))\n",
    "\n",
    "            output_review.append(lemmatizer_word)\n",
    "\n",
    "    return output_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8514bf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(clean_review(doc), category) for doc, category in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d739bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for doc in documents:\n",
    "    all_words += doc[0]\n",
    "\n",
    "frequency = FreqDist(all_words)\n",
    "\n",
    "common_words = frequency.most_common(3000)\n",
    "vocab_words = [word[0] for word in common_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cfde7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "\n",
    "    for word in vocab_words:\n",
    "        features[word] = (word in document_words)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27412ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = [(get_document_features(doc), category) for doc, category in documents[:1600]]\n",
    "test_set = [(get_document_features(doc), category) for doc, category in documents[1600:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc75c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import NaiveBayesClassifier\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf46ae9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7575"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.classify import accuracy\n",
    "\n",
    "accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63e5f0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(RandomForestClassifier())>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "random_forest = SklearnClassifier(RandomForestClassifier())\n",
    "\n",
    "random_forest.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bd65d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7925"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(random_forest, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38536a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = [category for _, category in documents]\n",
    "\n",
    "text_doc = [' '.join(doc) for doc, _ in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0d67866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(text_doc, category, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b7552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(max_features=2000, ngram_range=(1, 2), min_df=5, max_df=0.8)\n",
    "x_train_count_vector = count_vectorizer.fit_transform(x_train)\n",
    "x_test_count_vector = count_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156721c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['000', '10', '100', ..., 'young', 'young man', 'zero'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de7c03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.815"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_count_vector_classifier = SVC()\n",
    "\n",
    "svm_count_vector_classifier.fit(x_train_count_vector, y_train)\n",
    "\n",
    "svm_count_vector_classifier.score(x_test_count_vector, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2977c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=2000, ngram_range=(1, 2), min_df=5, max_df=0.8)\n",
    "x_train_tfidf_vector = tfidf_vectorizer.fit_transform(x_train)\n",
    "x_test_tfidf_vector = tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac522672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_tfidf_vector_classifier = SVC()\n",
    "\n",
    "svm_tfidf_vector_classifier.fit(x_train_tfidf_vector, y_train)\n",
    "\n",
    "svm_tfidf_vector_classifier.score(x_test_tfidf_vector, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
